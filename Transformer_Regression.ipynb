{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1pVkYEIe-gdTsQpTMsQPMtbDqulmL3ybN","authorship_tag":"ABX9TyN+Akaf9HudEyL8KYd47inS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"jh5G2SyQgj7Y"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim import Adam\n","from torch.utils.tensorboard import SummaryWriter\n","\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","\n","import math\n","import random\n","import pickle\n","import pandas as pd\n","import numpy as np\n","from matplotlib.pyplot import *\n","\n","try:\n","    import wandb\n","except:\n","    !pip install wandb -qqq\n","    import wandb\n","\n","import time\n","from datetime import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UR8SUWX2pSVN","executionInfo":{"status":"ok","timestamp":1648667519432,"user_tz":-120,"elapsed":25,"user":{"displayName":"Gabriele Agostino","userId":"09755571968699249879"}},"outputId":"3942b74e-15ff-402f-a449-e019341121e7"},"source":["DEVICE = torch.device( \"cuda\" )\n","print(\"DEVICE: \", torch.cuda.get_device_name(DEVICE))\n","\n","def from_numpy( x ):\n","    return torch.from_numpy( x ).type( torch.float ).to( DEVICE )\n","\n","def to_numpy( x ):\n","    return x.detach().cpu().numpy()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DEVICE:  Tesla P100-PCIE-16GB\n"]}]},{"cell_type":"code","metadata":{"id":"yE9U1u6OkCH8"},"source":["class SingleInstanceMetaClass(type):\n","    def __init__(self, name, bases, dic):\n","        self.__single_instance = None\n","        super().__init__(name, bases, dic)\n","\n","    def __call__(cls, *args, **kwargs):\n","        if cls.__single_instance:\n","            return cls.__single_instance\n","        single_obj = cls.__new__(cls)\n","        single_obj.__init__(*args, **kwargs)\n","        cls.__single_instance = single_obj\n","        return single_obj"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VMZwWQgzgp8Z"},"source":["class Dataloader( metaclass=SingleInstanceMetaClass ):\n","    \"\"\"\n","    Loads return and prices from the previously constructed dataset, a DataFrame, saved in pickle format\n","    \"\"\"\n","\n","    def __init__( self, file_path, moving_average ):\n","        \"\"\"\n","        file path:\n","            the path of the Dataframe in pickle format\n","        moving average:\n","            moving average window size applied to data\n","        \"\"\"\n","        #dataframe is loaded\n","        self.data_df = self.load_df( file_path, moving_average )\n","\n","        #number of assets\n","        self.assets = self.data_df.columns.get_level_values(0).unique()\n","\n","        #number of features\n","        self.features = self.data_df.columns.get_level_values(1).unique()\n","\n","    def load_df( self, file_path: str, moving_average: int ) -> pd.DataFrame :\n","        \"\"\"\n","        file path:\n","            the path of the Dataframe in pickle format\n","        moving average:\n","            moving average window size applied to data\n","\n","        returns:\n","            dataframe from file_path\n","        \"\"\"\n","        data_df = pd.read_pickle( file_path )\n","        data_df =  data_df.rolling( moving_average ).mean().dropna()\n","        return data_df\n","\n","    def load_prices( self, ) -> np.ndarray:\n","        \"\"\"\n","        returns numpy array of shape (number of days, number of assets, number of features)\n","        containing the OHCLV prices\n","        \"\"\"\n","        prices = []\n","        for asset in self.assets:\n","            to_append = self.data_df[asset][self.features].values\n","            prices.append( to_append )\n","\n","        #prices is [ days, assets, features ]\n","        prices = np.stack( prices, axis = 1)\n","        return prices\n","\n","    def load_returns( self, ):\n","        \"\"\"\n","        returns numpy array of shape (number of days, number of assets, number of features)\n","        \"\"\"\n","        self.returns_df = self.data_df.pct_change().fillna(0)\n","        returns = []\n","        for asset in self.assets:\n","            to_append = self.returns_df[asset][self.features].values\n","            returns.append( to_append )\n","\n","        #returns is [ days, assets, features ]\n","        returns = np.stack( returns, axis = 1)\n","        return returns\n","\n","class Dataset():\n","\n","    def __init__( self, params ):\n","        # dataloader instance\n","        self.loader = Dataloader( params.file_path, params.moving_average )\n","\n","        # we store the data for env accessibility\n","        self.returns = self.loader.load_returns() # returns are clippend and standardized\n","        self.true_returns = self.loader.load_returns() # returns are pct variations\n","\n","        # split the indices for training, validation and testing\n","        self.split_indices( params.test_portion, params.val_portion )\n","\n","        # clipping an normalizing the data\n","        self.scale_data( params.feature_clip, params.vol_clip)\n","\n","        # other useful parameters\n","        self.episode_length = params.b_size\n","        self.encoder_sequence_length = params.encoder_sequence_length\n","\n","    def split_indices( self, test_portion, val_portion ):\n","        \"\"\"\n","        test_portion: float\n","            test portion of the dataset\n","        val_portion: float\n","            validation portion of the dataset\n","\n","        split dataset indices in self.train_indices, self.val_indices, self.test_indices : np.ndarray\n","        in accord with the portions. validation portion and test portion are at the end of dataset\n","        i.e. closer to present.\n","        \"\"\"\n","\n","        num_periods = self.returns.shape[0]\n","        start_train_set_index = 0\n","        start_val_set_index = int( num_periods *( 1 - (test_portion + val_portion) ) )\n","        start_test_set_index = int( num_periods * ( 1 - val_portion ) )\n","\n","        self.train_indices = np.arange(start_train_set_index, start_val_set_index)\n","        self.val_indices = np.arange(start_val_set_index, start_test_set_index)\n","        self.train_val_indices = np.arange(start_train_set_index, start_test_set_index)\n","        self.test_indices = np.arange(start_test_set_index, num_periods)\n","\n","\n","    def scale_data( self, feature_clip = .02, vol_clip = .8):\n","        \"\"\"\n","        feature_clip: float\n","            clipping value for the OHCL features\n","        vol_clip: float\n","            clipping value for Volume\n","\n","        clip OHCLV data and for each asset, a StardardScaler scales OHCL data and another StandardScaler scales Volumes data\n","        Standardized data is stored self.returns\n","        Non standardized data is in sefl.true_returns\n","        \"\"\"\n","\n","        feature_returns = self.returns[:,:,:-1]\n","        volumes_returns = self.returns[:,:,-1:]\n","\n","        clipped_features = np.clip( feature_returns, - feature_clip , feature_clip )\n","        clipped_volumes = np.clip( volumes_returns, - vol_clip, vol_clip )\n","\n","\n","        features_std = clipped_features.copy()\n","        volumes_std = clipped_volumes.copy()\n","\n","        feature_scalers = {}\n","        volume_scalers = {}\n","\n","        #scale training data\n","        for i in range(features_std.shape[1]):\n","            feature_scalers[i] = StandardScaler()\n","            volume_scalers[i] = StandardScaler()\n","            features_std[self.train_val_indices, i, :] = feature_scalers[i].fit_transform(features_std[self.train_val_indices, i, :])\n","            volumes_std[self.train_val_indices,i,:] = volume_scalers[i].fit_transform( volumes_std[self.train_val_indices,i,:])\n","\n","            #scale validation data\n","            #features_std[self.val_indices, i, :] = feature_scalers[i].transform(features_std[self.val_indices, i, :])\n","            #volumes_std[self.val_indices,i,:] = volume_scalers[i].transform( volumes_std[self.val_indices,i,:])\n","\n","            #scale test data\n","            features_std[self.test_indices, i, :] = feature_scalers[i].transform(features_std[self.test_indices, i, :])\n","            volumes_std[self.test_indices,i,:] = volume_scalers[i].transform( volumes_std[self.test_indices,i,:])\n","\n","        self.returns = np.concatenate([features_std, volumes_std], axis = -1)\n","\n","\n","    def load_sequence_indices( self, ):\n","        \"\"\"\n","        return sequence_indices_encoder, reward_returns_indices\n","        sequence_indices_encoder are used for selecting transformer input from self.returns or self.true_returns in the training phase\n","        reward_returns_indices are used for reward or target\n","        \"\"\"\n","        #questo metodo viene usato nella parte di RL, in modo da poter eventualmente modificare load_sequence in caso si voglia fare multi step forecasting o altre modifiche alla\n","        #regressione con il transformer\n","        indices = self.train_val_indices[ self.encoder_sequence_length : - self.episode_length ]\n","\n","        starting_index = np.random.choice( indices )\n","        sequence_indices = np.arange( starting_index, starting_index + self.episode_length )\n","        sequence_indices_encoder = []\n","        for i in range( self.episode_length ):\n","            sequence_indices_encoder.append( np.arange( sequence_indices[i] - self.encoder_sequence_length, sequence_indices[i] ) )\n","        #to be consistent with sequence indices selected above, having used arange we have to add one\n","        sequence_indices_encoder = 1 + np.array( sequence_indices_encoder )\n","\n","        reward_returns_indices = sequence_indices + 1\n","\n","        return sequence_indices_encoder, reward_returns_indices\n","\n","\n","    def load_sequence_and_targets( self, ):\n","        \"\"\"\n","        return transformer_input_sequence, regression_target_sequence\n","        sequence_indices_encoder sequence of standardized data to be used as transformer input\n","        regression_target_sequence are closing returns, target for regression\n","        \"\"\"\n","        indices = self.train_val_indices[ self.encoder_sequence_length : - self.episode_length ]\n","\n","        starting_index = np.random.choice( indices )\n","        sequence_indices = np.arange( starting_index, starting_index + self.episode_length )\n","        sequence_indices_transformer = []\n","        for i in range( self.episode_length ):\n","            sequence_indices_transformer.append( np.arange( sequence_indices[i] - self.encoder_sequence_length, sequence_indices[i] ) )\n","        #to be consistent with sequence indices selected above, having used arange we have to add one\n","        sequence_indices_transformer = 1 + np.array( sequence_indices_transformer )\n","\n","        target_returns_indices = sequence_indices + 1\n","\n","        transformer_input_sequence = self.returns[ sequence_indices_transformer ]\n","\n","        #since the prediction is passed as input for actor and critic, standardized returns are target\n","        regression_target_sequence = self.true_returns[ target_returns_indices, :, -2 ]\n","\n","        return transformer_input_sequence, regression_target_sequence\n","\n","    def load_test_sequence_and_targets( self, ):\n","        \"\"\"\n","        return transformer_input_sequence, regression_target_sequence\n","        sequence_indices_encoder sequence of standardized data to be used as transformer input\n","        regression_target_sequence are closing returns, target for regression\n","        \"\"\"\n","        indices = self.test_indices[ self.encoder_sequence_length : ]\n","\n","        sequence_indices_transformer = []\n","        for index in indices:\n","            sequence_indices_transformer.append( np.arange( index - self.encoder_sequence_length, index ) )\n","\n","        #to be consistent with sequence indices selected above, having used arange we have to add one\n","        sequence_indices_transformer = 1 + np.array( sequence_indices_transformer )\n","        sequence_indices_transformer = sequence_indices_transformer[:-1]\n","\n","        target_returns_indices = indices + 1\n","        target_returns_indices = target_returns_indices[:-1]\n","\n","        transformer_input_sequence = self.returns[ sequence_indices_transformer ]\n","\n","        regression_target_sequence = self.true_returns[ target_returns_indices, :, -2 ]\n","\n","        return transformer_input_sequence, regression_target_sequence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"flbTbpE6mvzd"},"source":["class NormalizationLayer( nn.Module ):\n","\n","    def __init__( self, d_model, epsilon = 1e-6 ):\n","        super( NormalizationLayer, self ).__init__()\n","        self.epsilon = epsilon\n","        self.w = nn.Parameter( torch.ones( d_model ) )\n","        self.b = nn.Parameter( torch.zeros( d_model ) )\n","\n","    def forward( self, x ):\n","        mean = x.mean( dim = -1, keepdim = True )\n","        std = x.std( dim = -1, keepdim = True )\n","        return self.w * ( x - mean ) / ( std + self.epsilon ) + self.b\n","\n","# as in https://timeseriestransformer.readthedocs.io/en/latest/README.html#installation the embedding layer is replaced by a generic linear layer\n","class EmbeddingLayer( nn.Module ):\n","\n","    def __init__( self, in_features, out_features ):\n","        super( EmbeddingLayer, self ).__init__()\n","        self.embedding = nn.Linear(in_features, out_features)\n","\n","    def forward( self, x ):\n","        return self.embedding(x)\n","\n","\n","class Time2Vec( nn.Module ):\n","    \"\"\"\n","    Time2Vec implementation\n","\n","    parameters\n","    in_features: int\n","        number of features of the data\n","    out_features: int\n","        number of out features (k in the original paper)\n","    activation_function: function or function like\n","        the activation function. If none, sin is used\n","    \"\"\"\n","\n","    def __init__( self, in_features, out_features, activation_function = None ):\n","        super(Time2Vec, self).__init__()\n","\n","        #i = 0\n","        self.linear_transformation = nn.Linear( in_features, 1, bias = True )\n","\n","        #1 <= i <= k\n","        self.periodic_transformation = nn.Linear( in_features, out_features - 1, bias = True)\n","\n","        if activation_function == None:\n","            self.activation_function = torch.sin\n","\n","    def forward( self, x ):\n","        # x has shape (sequence_length, in_features)\n","\n","        # linear_x has shape (sequence_length, 1)\n","        linear_x = self.linear_transformation( x )\n","\n","        # periodic_x has shape (sequence_length, out_features - 1)\n","        periodic_x = self.activation_function( self.periodic_transformation(x) )\n","\n","        # periodic_x has shape (sequence_length, out_features )\n","        out = torch.cat( [linear_x, periodic_x], dim = -1 )\n","\n","        return out\n","\n","\n","class Query( nn.Module ):\n","\n","    def __init__( self, in_features, out_features ):\n","        super( Query, self ).__init__()\n","        self.linear_layer = nn.Linear(in_features, out_features)\n","\n","    def forward( self, x ):\n","        x = self.linear_layer( x )\n","        return x\n","\n","\n","\n","class Key( nn.Module ):\n","\n","    def __init__( self, in_features, out_features ):\n","        super( Key, self ).__init__()\n","        self.linear_layer = nn.Linear(in_features, out_features)\n","\n","    def forward( self, x ):\n","        x = self.linear_layer( x )\n","        return x\n","\n","\n","\n","class Value( nn.Module ):\n","\n","    def __init__( self, in_features, out_features ):\n","        super( Value, self ).__init__()\n","        self.linear_layer = nn.Linear(in_features, out_features)\n","\n","    def forward( self, x ):\n","        x = self.linear_layer( x )\n","        return x\n","\n","\n","class MultiHeadAttention( nn.Module ):\n","\n","    def __init__( self, in_features, d_model, num_heads ):\n","        super( MultiHeadAttention, self ).__init__()\n","\n","        assert d_model % num_heads == 0\n","\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.depth = d_model // num_heads\n","\n","        self.query = Query( in_features, d_model )\n","        self.key = Key( in_features, d_model )\n","        self.value = Value( in_features, d_model )\n","\n","    def attention( self, query, key, value ):\n","        matmul_qk = torch.matmul( query, key.transpose(-2, -1) )\n","        scaled_attention_logits = matmul_qk / math.sqrt( self.depth )\n","        attention_weights = F.softmax( scaled_attention_logits, dim = -1 )\n","        output = torch.matmul( attention_weights, value )\n","        return output, attention_weights\n","\n","    def forward( self, query, key, value ):\n","\n","        companies = query.size(0)\n","\n","        #linear transformation [ assets, sequence_length, d_model]\n","        query = self.query( query )\n","        key = self.key( key )\n","        value = self.value( value )\n","\n","        # splitting in num_heads -> [ assets, sequence_length, num_heads, depth]\n","        query = query.contiguous().view( companies, -1 , self.num_heads, self.depth )\n","        key = key.contiguous().view( companies, -1 , self.num_heads, self.depth )\n","        value = value.contiguous().view( companies, -1 , self.num_heads, self.depth )\n","\n","        # [ assets, sequence_length, num_heads, depth]\n","        # -> [ assets, num_heads, sequence_length, depth]\n","        query = query.transpose( 2, 1 )\n","        key = key.transpose( 2, 1 )\n","        value = value.transpose( 2, 1 )\n","\n","        # applying attention\n","        # output [ assets, num_heads, sequence_length, depth]\n","        # attention_weights [ assets, num_heads, sequence_length_q, sequence_length_k]\n","        output, attention_weights = self.attention( query, key, value )\n","\n","        # [ assets, num_heads, sequence_length, depth]\n","        # -> [ assets, sequence_length, num_heads, depth]\n","        output = output.transpose( 2, 1 )\n","\n","        # [ assets, seq_len, d_model ]\n","        return output.contiguous().view( companies, -1 , self.d_model)\n","\n","\n","class FeedForward( nn.Module ):\n","\n","    def __init__( self, in_features, n_layers, d_layers, out_features, dropout ):\n","        super( FeedForward, self ).__init__()\n","\n","        layers = nn.ModuleList([])\n","\n","        if n_layers > 1:\n","            layers.append( nn.Linear( in_features, d_layers ) )\n","            layers.append( nn.LeakyReLU() )\n","            for layer_index in range( n_layers - 1 ):\n","                layers.append( nn.Linear( d_layers, d_layers))\n","                layers.append( nn.LeakyReLU() )\n","                layers.append( nn.Dropout( dropout ) )\n","            layers.append( nn.Linear( d_layers, out_features ) )\n","        else:\n","            layers.append( nn.Linear( in_features, out_features ))\n","\n","        self.net = nn.Sequential( *layers )\n","\n","    def forward( self, x ):\n","        x = self.net(x)\n","        return x\n","\n","\n","class EncoderLayer( nn.Module ):\n","\n","    def __init__( self, d_model, in_features, n_layers_ff, d_layers_ff, num_heads, dropout ):\n","        super( EncoderLayer, self ).__init__()\n","        self.norm_layer1 = NormalizationLayer( d_model )\n","        self.norm_layer2 = NormalizationLayer( d_model )\n","        self.dropout_layer1 = nn.Dropout( dropout )\n","        self.dropout_layer2 = nn.Dropout( dropout )\n","        self.mha = MultiHeadAttention( in_features = in_features,\n","                                       d_model = d_model,\n","                                       num_heads = num_heads )\n","        self.ffnn = FeedForward( in_features = d_model,\n","                                 n_layers = n_layers_ff,\n","                                 d_layers = d_layers_ff,\n","                                 out_features = d_model,\n","                                 dropout = dropout )\n","\n","    def forward( self, x ):\n","        x2 = self.mha( x, x, x )\n","        x = self.norm_layer1( x + self.dropout_layer1(x2) )\n","        x2 = self.ffnn( x )\n","        return self.norm_layer2( x + self.dropout_layer2(x2) )\n","\n","\n","class DecoderLayer( nn.Module ):\n","\n","    def __init__( self, d_model, in_features, n_layers_ff, d_layers_ff, num_heads, dropout  ):\n","        super( DecoderLayer, self ).__init__()\n","        self.norm_layer1 = NormalizationLayer( d_model )\n","        self.norm_layer2 = NormalizationLayer( d_model )\n","        self.norm_layer3 = NormalizationLayer( d_model )\n","        self.dropout_layer1 = nn.Dropout( dropout )\n","        self.dropout_layer2 = nn.Dropout( dropout )\n","        self.dropout_layer3 = nn.Dropout( dropout )\n","        self.mha1 = MultiHeadAttention( in_features = in_features,\n","                                       d_model = d_model,\n","                                       num_heads = num_heads )\n","        self.mha2 = MultiHeadAttention( in_features = in_features,\n","                                       d_model = d_model,\n","                                       num_heads = num_heads )\n","        self.ffnn = FeedForward( in_features = d_model,\n","                                 n_layers = n_layers_ff,\n","                                 d_layers = d_layers_ff,\n","                                 out_features = d_model,\n","                                 dropout = dropout )\n","\n","    def forward( self, x, encoder_output ):\n","        x2 = self.mha1( x, x, x )\n","        x = self.norm_layer1( x + self.dropout_layer1(x2) )\n","        x2 = self.mha2( query = x, key = encoder_output, value = encoder_output )\n","        x = self.norm_layer2( x + self.dropout_layer2(x2) )\n","        x2 = self.ffnn( x )\n","\n","        return self.norm_layer3( x + self.dropout_layer3(x2) )\n","\n","\n","\n","class Encoder( nn.Module ):\n","\n","    def __init__( self,\n","                 d_model,\n","                 num_layers,\n","                 num_heads,\n","                 t2v_units,\n","                 sequence_length,\n","                 num_features,\n","                 num_ff_layers,\n","                 dim_ff_layers,\n","                 dropout\n","                ):\n","        super( Encoder, self ).__init__()\n","\n","        self.t2v_layer = Time2Vec( in_features = num_features,\n","                                   out_features =  t2v_units )\n","        self.embedding_layer = EmbeddingLayer( num_features + t2v_units, d_model )\n","        self.encoder_layers = self.get_layers( num_layers = num_layers,\n","                                               d_model = d_model,\n","                                               num_ff_layers = num_ff_layers,\n","                                               dim_ff_layers = dim_ff_layers,\n","                                               num_heads = num_heads,\n","                                               dropout = dropout )\n","\n","    def get_layers( self, num_layers, d_model, num_ff_layers, dim_ff_layers, num_heads, dropout ):\n","        return nn.ModuleList( [EncoderLayer( d_model = d_model, \\\n","                                             in_features = d_model, \\\n","                                             n_layers_ff = num_ff_layers, \\\n","                                             d_layers_ff = dim_ff_layers, \\\n","                                             num_heads = num_heads,\n","                                             dropout = dropout ) \\\n","                                for _ in range(num_layers)] )\n","\n","    def forward( self, x ):\n","        #input is [companies, sequence_length, features]\n","\n","        #t2v output is [companies, sequence_length, t2v_units]\n","        x2 = self.t2v_layer(x)\n","\n","        #x is [companies, sequence_length, features + t2v_units]\n","        x = torch.cat( [ x, x2 ], dim = -1)\n","\n","        #x is [companies, sequence_length, d_model]\n","        x = self.embedding_layer( x )\n","\n","        for encoder_layer in self.encoder_layers:\n","            x = encoder_layer(x)\n","\n","        return x\n","\n","\n","class Decoder( nn.Module ):\n","\n","    def __init__( self,\n","                  d_model,\n","                  num_layers,\n","                  num_heads,\n","                  t2v_units,\n","                  sequence_length,\n","                  num_features,\n","                  num_ff_layers,\n","                  dim_ff_layers,\n","                  dropout ):\n","        super( Decoder, self ).__init__()\n","        self.t2v_layer = Time2Vec( in_features = num_features,\n","                                   out_features =  t2v_units )\n","        self.embedding_layer = EmbeddingLayer( num_features + t2v_units, d_model )\n","        self.decoder_layers = self.get_layers( num_layers = num_layers,\n","                                               d_model = d_model,\n","                                               num_ff_layers = num_ff_layers,\n","                                               dim_ff_layers = dim_ff_layers,\n","                                               num_heads = num_heads,\n","                                               dropout = dropout )\n","\n","    def get_layers( self, num_layers, d_model, num_ff_layers, dim_ff_layers, num_heads, dropout ):\n","        return nn.ModuleList( [DecoderLayer( d_model = d_model, \\\n","                                             in_features = d_model, \\\n","                                             n_layers_ff = num_ff_layers, \\\n","                                             d_layers_ff = dim_ff_layers, \\\n","                                             num_heads = num_heads,\n","                                             dropout = dropout ) \\\n","                                for _ in range(num_layers)] )\n","\n","    def forward( self, x, encoder_output ):\n","        #input x is [companies, sequence_length, features]\n","        #encoder output is [ companies, sequence_length, encoder dimension]\n","\n","        #t2v output is [batch size, companies, sequence_length, t2v_units]\n","        x2 = self.t2v_layer(x)\n","\n","        #x is [batch size, companies, sequence_length, features + t2v_units]\n","        x = torch.cat( [ x, x2 ], dim = -1)\n","\n","        #x is [batch size, companies, sequence_length, d_model]\n","        x = self.embedding_layer( x )\n","\n","        for decoder_layer in self.decoder_layers:\n","            x = decoder_layer(x, encoder_output)\n","\n","        return x\n","\n","\n","\n","class Transformer( nn.Module ):\n","\n","    def __init__( self,\n","                 dim_transformer,\n","                 encoder_sequence_length,\n","                 decoder_sequence_length,\n","                 num_layers,\n","                 num_heads,\n","                 t2v_units,\n","                 num_features,\n","                 num_ff_layers,\n","                 dim_ff_layers,\n","                 dropout\n","                ):\n","        super ( Transformer, self ).__init__()\n","        self.encoder = Encoder( d_model = dim_transformer,\n","                                num_layers = num_layers,\n","                                num_heads = num_heads,\n","                                t2v_units = t2v_units,\n","                                sequence_length = encoder_sequence_length,\n","                                num_features = num_features,\n","                                num_ff_layers = num_ff_layers,\n","                                dim_ff_layers = dim_ff_layers,\n","                                dropout = dropout\n","                               )\n","        self.decoder = Decoder( d_model = dim_transformer,\n","                                num_layers = num_layers,\n","                                num_heads = num_heads,\n","                                t2v_units = t2v_units,\n","                                sequence_length = decoder_sequence_length,\n","                                num_features = num_features,\n","                                num_ff_layers = num_ff_layers,\n","                                dim_ff_layers = dim_ff_layers,\n","                                dropout = dropout\n","                               )\n","\n","        self.decoder_sequence_ffnn = FeedForward( in_features = decoder_sequence_length, n_layers = num_ff_layers, d_layers = dim_ff_layers, out_features = 1, dropout = dropout )\n","\n","\n","        self.decoder_sequence_length = decoder_sequence_length\n","\n","    def forward( self, x ):\n","\n","        #[  encoder_sequence_length, companies, features] -> [ companies, encoder_sequence_length, features]\n","        x = x.transpose(1,0)\n","\n","        #input x is for encoder [ companies, encoder_sequence_length, features]\n","        xe = x\n","\n","        #input xd is for decoder [ companies, decoder_sequence_length, features]\n","        xd = x[:,-self.decoder_sequence_length:]\n","\n","        #[ companies, encoder_sequence_length, d_model_encoder]\n","        encoder_output = self.encoder(xe)\n","\n","        #[ companies, decoder_sequence_length, d_model_decoder]\n","        decoder_output = self.decoder(xd, encoder_output)\n","\n","        #[ companies, decoder_sequence_length, d_model_decoder] -> [ companies, d_model_decoder]\n","        output = self.decoder_sequence_ffnn( decoder_output.transpose(-2,-1) ).squeeze()\n","\n","        return output\n","\n","\n","class RegressionTransformer( nn.Module ):\n","\n","    def __init__( self, params ):\n","        super( RegressionTransformer, self ).__init__()\n","\n","        self.transformer = Transformer( params.dim_transformer,\n","                                        params.encoder_sequence_length,\n","                                        params.decoder_sequence_length,\n","                                        params.num_layers,\n","                                        params.num_heads,\n","                                        params.t2v_units,\n","                                        params.num_features,\n","                                        params.num_ff_layers,\n","                                        params.dim_ff_layers,\n","                                        params.dropout\n","                                        )\n","\n","        self.ffnn = FeedForward( params.dim_transformer, params.regression_ff_layers, params.dim_regression_ff_layers, 1, params.dropout)\n","\n","    def forward( self, x):\n","        x = self.transformer(x)\n","        x = self.ffnn(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rVOaB-bAg174"},"source":["class Parameters(metaclass=SingleInstanceMetaClass):\n","\n","    def __init__(self,):\n","\n","        self.file_path =\n","        self.etfs = ['XLB', 'XLC', 'XLE', 'XLF', 'XLI', 'XLK', 'XLP', 'XLRE', 'XLU', 'XLV', 'XLY']\n","        self.moving_average = 10 # moving average smoothing to be applied to data\n","        self.val_portion = .1 #validation portion in dataset\n","        self.test_portion = .1 #test portion in dataset\n","        self.num_epochs = 300 # number of epochs\n","        self.b_size = 64 # batch size\n","\n","        self.dropout = 0.1 # probability of an element to be zeroed in dropout layer\n","\n","        self.feature_clip = 0.02\n","        self.vol_clip = 0.8\n","\n","        self.encoder_sequence_length = 60 # sequence length for encoder input\n","        self.decoder_sequence_length = 20 # sequence length for decoder input\n","        self.dim_transformer = 64  #transformer model dimension\n","\n","        self.num_layers = 1 # number of stacked encoder and decoder layers\n","        self.num_heads = 2 # number of heads in each layer\n","        self.t2v_units = 16 # k in t2v paper\n","\n","        self.num_features = 5 #OHCLV\n","\n","        self.num_ff_layers = 3 # number of feedforward layers in encoder and decoder layers\n","        self.dim_ff_layers = 256 #dimension of of feedforward layers in encoder and decoder layers\n","\n","        self.regression_ff_layers = 4 #  number of feedforward layers in encoder and decoder layers\n","        self.dim_regression_ff_layers = 512 # dimension of feedforward layers in ffnn that produces prediction\n","\n","        self.schedule_lr = True # use noam scheduler as in \"attention\" is all you need\n","        self.noam_model_size = 256\n","        self.noam_factor = .1\n","        self.noam_warmup = 2000\n","\n","        self.lr = 1e-3 # learning rate in adam optimizer if not using noam scheduler\n","        self.beta1 = .9 # beta1 parameter in adam optimizer\n","        self.beta2 = .99 # beta2 parameter in adam optimizer\n","\n","        self.early_stopping = True # use or not early stopping. I don't use a min_delta so every improvement is an improvement.\n","        self.patience = 5 # number of epochs with no improvement after which training will be stopped.\n","\n","        self.seed = 1 # seed for reproducibility\n","\n","        self.loss = \"lch\" #loss to use, mse or mae or lch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OXVWS5Dtjvs1"},"source":["#losses and metrics\n","mse_loss = nn.MSELoss()\n","mae_loss = nn.L1Loss()\n","\n","def log_cosh_loss( output, target ):\n","    return torch.mean(torch.log(torch.cosh(target - output + 1e-12)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7KRJgGeask17"},"source":["def noam_scheduler( step, factor, model_size, warmup ):\n","    step += 1\n","    return factor * (model_size ** (-0.5) * min(step ** (-0.5), step * warmup ** (-1.5)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RYpVhgHFszDj","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1648668503930,"user_tz":-120,"elapsed":983542,"user":{"displayName":"Gabriele Agostino","userId":"09755571968699249879"}},"outputId":"b037fda9-e37f-4573-f872-dcbf69335d67"},"source":["#initalization of weights and parameters\n","p = Parameters()\n","d = Dataset( p )\n","#adding number of batches per epoch\n","p.batch_per_epoch = int(d.train_indices.shape[0] / p.b_size)\n","\n","#setting seeds\n","torch.manual_seed( p.seed )\n","random.seed( p.seed )\n","np.random.seed( p.seed )\n","torch.backends.cudnn.deterministic = True\n","\n","#run name for wandb and tensorboard\n","run_name = f\"Transformer_Regression__{p.seed}__{int(time.time())}\"\n","\n","#weights and biases and tensorboard\n","wandb.init(\n","    project = ,\n","    entity = ,\n","    sync_tensorboard=True,\n","    config = vars(p),\n","    name = run_name,\n","    save_code = True\n",")\n","\n","writer = SummaryWriter()\n","writer.add_text(\n","        \"hyperparameters\",\n","        \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in vars(p).items()])),\n","    )\n","\n","#save plot of scheduled lr for the run\n","steps_to_do = np.arange( p.num_epochs * p.batch_per_epoch)\n","fig = figure()\n","title(\"Learning rate \")\n","plot([noam_scheduler( step, p.noam_factor, p.noam_model_size, p.noam_warmup) for step in steps_to_do] )\n","xlabel(\"Step (#)\")\n","ylabel(\"Learning rate (#)\")\n","writer.add_figure(\"plots/scheduled_lr\", fig, 0)\n","\n","\n","#initializing model and optimizer\n","r = RegressionTransformer( p ).to( DEVICE )\n","optim = Adam( r.parameters(), lr = p.lr, betas = (p.beta1, p.beta2) )\n","\n","\n","#init values for early stopping\n","current_min_val_loss = 1e8\n","epochs_wo_improve = 0\n","\n","#parameter for noam scheduler\n","global_step = 0\n","\n","#for epoch time printing\n","start_time = time.time()\n","\n","#training\n","for epoch in range(p.num_epochs):\n","    print(f\"EPOCH {epoch} / {p.num_epochs}\")\n","\n","    #metrics and losses in epoch\n","    ep_mse_losses = []\n","    ep_mae_losses = []\n","    ep_lch_losses = []\n","\n","    #training\n","    for step in range(p.batch_per_epoch):\n","\n","        #since lr is update after each step() method call the lr scheduling is done here https://nlp.seas.harvard.edu/2018/04/03/attention.html#optimizer\n","        if p.schedule_lr:\n","            #update lr\n","            lr_now = noam_scheduler( global_step, p.noam_factor, p.noam_model_size, p.noam_warmup )\n","            optim.param_groups[0]['lr'] = lr_now\n","\n","        #metrics and losses in batch\n","        mse_losses = []\n","        mae_losses = []\n","        lch_losses = []\n","\n","        #data is loaded from dataset\n","        xs_transformer, ys = d.load_sequence_and_targets()\n","\n","        #data is converted to torch tensor\n","        xs_transformer = from_numpy(xs_transformer)\n","        ys = from_numpy( ys ).unsqueeze(-1)\n","\n","        #zero_grad\n","        optim.zero_grad()\n","\n","        #model is in training phase\n","        r.train()\n","\n","        for x, y in zip( xs_transformer, ys ):\n","\n","            #prediction\n","            y_pred = r( x )\n","\n","            #losses and metrics\n","            mse = mse_loss( y_pred, y )\n","            mae = mae_loss( y_pred, y )\n","            lch = log_cosh_loss( y_pred, y )\n","\n","            mse_losses.append(mse.item())\n","            mae_losses.append(mae.item())\n","            lch_losses.append(lch.item())\n","\n","            #backward\n","            if p.loss == \"mse\":\n","                mse.backward()\n","            if p.loss == \"mae\":\n","                mae.backward()\n","            if p.loss == \"lch\":\n","                lch.backward()\n","\n","        # opt step and update counter for noam scheduler\n","        optim.step()\n","        global_step += 1\n","\n","        ep_mse_losses.append(torch.mean(torch.FloatTensor(mse_losses)).item())\n","        ep_mae_losses.append(torch.mean(torch.FloatTensor(mae_losses)).item())\n","        ep_lch_losses.append(torch.mean(torch.FloatTensor(lch_losses)).item())\n","\n","        #register lr in writer\n","        writer.add_scalar(\"charts/learning rate\", optim.param_groups[0]['lr'], global_step)\n","\n","\n","    #register losses in writer\n","    writer.add_scalar(\"mse_loss/train\", torch.mean(torch.FloatTensor(ep_mse_losses)).item(), epoch)\n","    writer.add_scalar(\"mae_loss/train\", torch.mean(torch.FloatTensor(ep_mae_losses)).item(), epoch)\n","    writer.add_scalar(\"lch_loss/train\", torch.mean(torch.FloatTensor(ep_lch_losses)).item(), epoch)\n","\n","\n","    #validation\n","    #validation data is loaded\n","    xs_transformer, ys = d.load_test_sequence_and_targets()\n","\n","    #data is converted to torch tensor\n","    val_xs_transformer = from_numpy(xs_transformer)\n","    val_ys = from_numpy( ys ).unsqueeze(-1)\n","    val_y_preds = []\n","\n","    #model is in evaluating phase\n","    r.eval()\n","\n","    for x, y in zip( val_xs_transformer, val_ys ):\n","\n","        with torch.no_grad():\n","            y_pred = r( x )\n","            val_y_preds.append( y_pred )\n","\n","    #convert predictions to torch tensor\n","    val_y_preds = torch.stack(val_y_preds)\n","\n","    #compute losses and metrics on validation set\n","    val_mse = mse_loss( val_y_preds, val_ys )\n","    val_mae = mae_loss( val_y_preds, val_ys )\n","    val_lch = log_cosh_loss( val_y_preds, val_ys )\n","\n","    #register validation losses in writer\n","    writer.add_scalar(\"mse_loss/test\", val_mse.item(), epoch)\n","    writer.add_scalar(\"mae_loss/test\", val_mae.item(), epoch)\n","    writer.add_scalar(\"lch_loss/test\", val_lch.item(), epoch)\n","\n","    # plot predictions\n","    val_ys = to_numpy( val_ys )\n","    val_y_preds = to_numpy( val_y_preds )\n","\n","    fig, axs = subplots( len(p.etfs), 1 , figsize = (20,25))\n","    fig.suptitle( \"Predictions on test set\", fontsize = 18)\n","    fig.subplots_adjust(top= .95)\n","    for i in range(len(p.etfs)):\n","        axs[i].set_title(p.etfs[i])\n","        axs[i].plot(val_ys[:,i,0], label = \"True\")\n","        axs[i].plot(val_y_preds[:,i,0], label = \"Predicted\")\n","        axs[i].legend()\n","        axs[i].set_ylabel(\"Return (#)\")\n","        if i!=10:\n","            axs[i].set_xticklabels([])\n","        if i==10:\n","            axs[i].set_xlabel(\"Day from start of set (#)\")\n","\n","    #register figure in writer\n","    writer.add_figure(\"plots/test\", fig, epoch)\n","\n","\n","    #print statements at epoch end\n","    print(\"{:.2f}s\".format( time.time() - start_time ) )\n","    print(f\"mse loss {torch.mean(torch.FloatTensor(ep_mse_losses)).item()} - on test {val_mse.item()}\")\n","    print(f\"mae loss {torch.mean(torch.FloatTensor(ep_mae_losses)).item()} -  on test {val_mae.item()}\")\n","    print(f\"log cosh loss {torch.mean(torch.FloatTensor(ep_lch_losses)).item()} - on test {val_lch.item()}\")\n","    start_time = time.time()\n","\n","    #early stopping\n","    if p.loss == \"mse\":\n","        val_loss = val_mse.item()\n","    if p.loss == \"mae\":\n","        val_loss = val_mae.item()\n","    if p.loss == \"lch\":\n","        val_loss = val_lch.item()\n","\n","\n","    #patience found via validation with value of 24\n","    epochs_wo_improve += 1\n","    if epochs_wo_improve == 24:\n","        print(f\"Stopping at epoch {epoch}\")\n","        torch.save(r, f\"/content/drive/MyDrive/0_Codice tesi/RUN_DEF/pesi/regression_weights2.pt\")\n","        break\n","\n","    #if p.early_stopping:\n","    #    if val_loss < current_min_val_loss:\n","    #        #update value of min val loss and reset number of epochs without improvement\n","    #        current_min_val_loss = val_loss\n","    #        epochs_wo_improve = 0\n","#\n","    #        #save model weights\n","    #        torch.save(r, f\"/content/drive/MyDrive/Codice tesi/Regression_logs/{run_name}/regression_weights.pt\")\n","    #        print(\"saved model weights\")\n","#\n","    #    else:\n","    #        epochs_wo_improve += 1\n","    #\n","    #    #if early stopping condition is met stop training\n","    #    if epochs_wo_improve == p.patience:\n","    #        print(f\"Early stopping at epoch {epoch}\")\n","    #        break\n","\n","\n","writer.close()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m4g0\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.11"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20220330_191206-2x2d01ql</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/4g0/DEF/runs/2x2d01ql\" target=\"_blank\">Transformer_Regression__1__1648667520</a></strong> to <a href=\"https://wandb.ai/4g0/DEF\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["EPOCH 0 / 300\n","39.22s\n","mse loss 0.0011333436705172062 - on test 0.0005115600652061403\n","mae loss 0.032831043004989624 -  on test 0.0219098050147295\n","log cosh loss 0.000566544127650559 - on test 0.0002557481930125505\n","EPOCH 1 / 300\n","41.21s\n","mse loss 0.00015285349218174815 - on test 3.445145193836652e-05\n","mae loss 0.009837673977017403 -  on test 0.004013993311673403\n","log cosh loss 7.641877164132893e-05 - on test 1.721938133414369e-05\n","EPOCH 2 / 300\n","39.82s\n","mse loss 4.204979632049799e-05 - on test 3.083033152506687e-05\n","mae loss 0.005005711689591408 -  on test 0.0034751631319522858\n","log cosh loss 2.10198213608237e-05 - on test 1.54077097249683e-05\n","EPOCH 3 / 300\n","39.75s\n","mse loss 4.0883212932385504e-05 - on test 2.7930438591283746e-05\n","mae loss 0.004903003573417664 -  on test 0.0031304301228374243\n","log cosh loss 2.0436718841665424e-05 - on test 1.3957087503513321e-05\n","EPOCH 4 / 300\n","39.93s\n","mse loss 3.094307248829864e-05 - on test 2.184652112191543e-05\n","mae loss 0.0043372781947255135 -  on test 0.0028948751278221607\n","log cosh loss 1.5466297554667108e-05 - on test 1.0916244718828239e-05\n","EPOCH 5 / 300\n","40.06s\n","mse loss 2.6066856662509963e-05 - on test 1.8585613361210562e-05\n","mae loss 0.0039538005366921425 -  on test 0.002577324630692601\n","log cosh loss 1.302763121202588e-05 - on test 9.2848140411661e-06\n","EPOCH 6 / 300\n","39.53s\n","mse loss 1.8810462279361673e-05 - on test 1.6049518308136612e-05\n","mae loss 0.003411982674151659 -  on test 0.002248454373329878\n","log cosh loss 9.399386726727244e-06 - on test 8.017387699510437e-06\n","EPOCH 7 / 300\n","39.58s\n","mse loss 1.5550001990050077e-05 - on test 1.4546320016961545e-05\n","mae loss 0.0030349004082381725 -  on test 0.0023114474024623632\n","log cosh loss 7.768924660922494e-06 - on test 7.265372460096842e-06\n","EPOCH 8 / 300\n","39.96s\n","mse loss 1.3829125236952677e-05 - on test 1.2773578419000842e-05\n","mae loss 0.0027825937140733004 -  on test 0.0020959354005753994\n","log cosh loss 6.908516297698952e-06 - on test 6.379207661666442e-06\n","EPOCH 9 / 300\n","42.25s\n","mse loss 9.774269528861623e-06 - on test 1.1972591892117634e-05\n","mae loss 0.002412844682112336 -  on test 0.0018953148974105716\n","log cosh loss 4.880267169937724e-06 - on test 5.978262834105408e-06\n","EPOCH 10 / 300\n","40.13s\n","mse loss 9.135690561379306e-06 - on test 9.947813850885723e-06\n","mae loss 0.002313272561877966 -  on test 0.0017843774985522032\n","log cosh loss 4.561239165923325e-06 - on test 4.966229880665196e-06\n","EPOCH 11 / 300\n","40.26s\n","mse loss 9.597133612260222e-06 - on test 9.674574357632082e-06\n","mae loss 0.0022881522309035063 -  on test 0.0017448934959247708\n","log cosh loss 4.792007075593574e-06 - on test 4.828423243452562e-06\n","EPOCH 12 / 300\n","39.81s\n","mse loss 8.011245881789364e-06 - on test 9.499800398771185e-06\n","mae loss 0.002128007123246789 -  on test 0.0017741563497111201\n","log cosh loss 3.998518877779134e-06 - on test 4.7420785449503455e-06\n","EPOCH 13 / 300\n","39.62s\n","mse loss 7.915794412838295e-06 - on test 1.0251537787553389e-05\n","mae loss 0.002064122585579753 -  on test 0.0018759943777695298\n","log cosh loss 3.950937752961181e-06 - on test 5.117233740747906e-06\n","EPOCH 14 / 300\n","39.90s\n","mse loss 6.10094548392226e-06 - on test 9.490166121395305e-06\n","mae loss 0.0018799472600221634 -  on test 0.0017570196650922298\n","log cosh loss 3.0435260214289883e-06 - on test 4.737710696645081e-06\n","EPOCH 15 / 300\n","39.70s\n","mse loss 6.214319455466466e-06 - on test 9.04050739336526e-06\n","mae loss 0.0018454811070114374 -  on test 0.00171847699675709\n","log cosh loss 3.100253934462671e-06 - on test 4.512275154411327e-06\n","EPOCH 16 / 300\n","40.01s\n","mse loss 6.691901944577694e-06 - on test 8.742092177271843e-06\n","mae loss 0.0019072340801358223 -  on test 0.0016993137542158365\n","log cosh loss 3.338725946377963e-06 - on test 4.363317202660255e-06\n","EPOCH 17 / 300\n","40.21s\n","mse loss 5.266905191092519e-06 - on test 8.745239028939977e-06\n","mae loss 0.0017240112647414207 -  on test 0.001663787174038589\n","log cosh loss 2.6264010557497386e-06 - on test 4.3647819438774604e-06\n","EPOCH 18 / 300\n","39.82s\n","mse loss 7.015079972916283e-06 - on test 8.675428944115993e-06\n","mae loss 0.0018876803806051612 -  on test 0.0018368589226156473\n","log cosh loss 3.5004829896934098e-06 - on test 4.329742750996957e-06\n","EPOCH 19 / 300\n","39.69s\n","mse loss 5.793248419649899e-06 - on test 7.848207133065443e-06\n","mae loss 0.001782958977855742 -  on test 0.0016182432882487774\n","log cosh loss 2.8894439765281277e-06 - on test 3.915277375199366e-06\n","EPOCH 20 / 300\n","39.85s\n","mse loss 6.017142823111499e-06 - on test 8.052199518715497e-06\n","mae loss 0.0017703649355098605 -  on test 0.0017789481207728386\n","log cosh loss 3.0016121854714584e-06 - on test 4.018947493023006e-06\n","EPOCH 21 / 300\n","39.83s\n","mse loss 5.994572802592302e-06 - on test 7.861988706281409e-06\n","mae loss 0.0017685226630419493 -  on test 0.0016494346782565117\n","log cosh loss 2.9902357709943317e-06 - on test 3.92236370316823e-06\n","EPOCH 22 / 300\n","39.76s\n","mse loss 6.231976385606686e-06 - on test 9.38726770982612e-06\n","mae loss 0.0018184243235737085 -  on test 0.0017981791170313954\n","log cosh loss 3.1091713026398793e-06 - on test 4.685630301537458e-06\n","EPOCH 23 / 300\n","39.79s\n","mse loss 6.3196093833539635e-06 - on test 9.628807674744166e-06\n","mae loss 0.0018064056057482958 -  on test 0.001737984362989664\n","log cosh loss 3.1527438295597676e-06 - on test 4.805702701560222e-06\n","Stopping at epoch 23\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"u-2fIZIUB-4G"},"execution_count":null,"outputs":[]}]}